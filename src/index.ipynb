{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %% [1] å®‰è£ä¾è³´ & å°å…¥åº«\n",
    "!pip install psycopg2-binary matplotlib pandas --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# é…ç½®æ•¸æ“šåº«é€£æ¥ (æ ¹æ“šä½ çš„ç’°å¢ƒä¿®æ”¹)\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# å»ºç«‹é€£æ¥\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¸¬è©¦è¡¨å‰µå»ºå®Œæˆï¼Œautovacuum å·²ç¦ç”¨\n",
      "ğŸ“¥ å·²æ’å…¥ 1000000 è¡Œåˆå§‹æ•¸æ“š\n"
     ]
    }
   ],
   "source": [
    "# %% [2] åˆå§‹åŒ–æ¸¬è©¦è¡¨\n",
    "def init_test_table():\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS test_fragmentation;\n",
    "            CREATE TABLE test_fragmentation (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                random_data TEXT,\n",
    "                created_at TIMESTAMP DEFAULT NOW()\n",
    "            );\n",
    "            ALTER TABLE test_fragmentation SET (autovacuum_enabled = off);\n",
    "        \"\"\")\n",
    "        print(\"âœ… æ¸¬è©¦è¡¨å‰µå»ºå®Œæˆï¼Œautovacuum å·²ç¦ç”¨\")\n",
    "        \n",
    "        # æ’å…¥åˆå§‹æ•¸æ“š\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO test_fragmentation (random_data)\n",
    "            SELECT md5(random()::text)\n",
    "            FROM generate_series(1, 1000000)\n",
    "        \"\"\")\n",
    "        print(f\"ğŸ“¥ å·²æ’å…¥ {cursor.rowcount} è¡Œåˆå§‹æ•¸æ“š\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆå§‹åŒ–éŒ¯èª¤: {str(e)}\")\n",
    "\n",
    "init_test_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™»ï¸ é€±æœŸ 1/10 | æ›´æ–°: 98102, åˆªé™¤: 39514, æ’å…¥: 200000 | è€—æ™‚: 1.3s\n",
      "â™»ï¸ é€±æœŸ 2/10 | æ›´æ–°: 178022, åˆªé™¤: 70881, æ’å…¥: 200000 | è€—æ™‚: 1.9s\n",
      "â™»ï¸ é€±æœŸ 3/10 | æ›´æ–°: 242497, åˆªé™¤: 97044, æ’å…¥: 200000 | è€—æ™‚: 2.1s\n",
      "â™»ï¸ é€±æœŸ 4/10 | æ›´æ–°: 294313, åˆªé™¤: 117860, æ’å…¥: 200000 | è€—æ™‚: 3.3s\n",
      "â™»ï¸ é€±æœŸ 5/10 | æ›´æ–°: 335783, åˆªé™¤: 134734, æ’å…¥: 200000 | è€—æ™‚: 3.4s\n",
      "â™»ï¸ é€±æœŸ 6/10 | æ›´æ–°: 367568, åˆªé™¤: 147134, æ’å…¥: 200000 | è€—æ™‚: 3.3s\n",
      "â™»ï¸ é€±æœŸ 7/10 | æ›´æ–°: 394356, åˆªé™¤: 157221, æ’å…¥: 200000 | è€—æ™‚: 3.1s\n",
      "â™»ï¸ é€±æœŸ 8/10 | æ›´æ–°: 415219, åˆªé™¤: 165758, æ’å…¥: 200000 | è€—æ™‚: 5.3s\n",
      "â™»ï¸ é€±æœŸ 9/10 | æ›´æ–°: 432903, åˆªé™¤: 173368, æ’å…¥: 200000 | è€—æ™‚: 3.2s\n",
      "â™»ï¸ é€±æœŸ 10/10 | æ›´æ–°: 446868, åˆªé™¤: 178552, æ’å…¥: 200000 | è€—æ™‚: 3.1s\n"
     ]
    }
   ],
   "source": [
    "# %% [3] è£½é€ ç¢ç‰‡åŒ–\n",
    "def create_fragmentation(cycles=10):\n",
    "    try:\n",
    "        for cycle in range(1, cycles+1):\n",
    "            start = time.time()\n",
    "            \n",
    "            # æ›´æ–°æ“ä½œ\n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE test_fragmentation\n",
    "                SET random_data = md5(random()::text)\n",
    "                WHERE random() < 0.5\n",
    "            \"\"\")\n",
    "            updated = cursor.rowcount\n",
    "            \n",
    "            # åˆªé™¤æ“ä½œ\n",
    "            cursor.execute(\"\"\"\n",
    "                DELETE FROM test_fragmentation\n",
    "                WHERE random() < 0.2\n",
    "            \"\"\")\n",
    "            deleted = cursor.rowcount\n",
    "            \n",
    "            # æ’å…¥æ“ä½œ\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO test_fragmentation (random_data)\n",
    "                SELECT md5(random()::text)\n",
    "                FROM generate_series(1, 200000)\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"â™»ï¸ é€±æœŸ {cycle}/{cycles} | \"\n",
    "                  f\"æ›´æ–°: {updated}, åˆªé™¤: {deleted}, æ’å…¥: {200000} | \"\n",
    "                  f\"è€—æ™‚: {time.time()-start:.1f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç¢ç‰‡åŒ–æ“ä½œéŒ¯èª¤: {str(e)}\")\n",
    "\n",
    "create_fragmentation(cycles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ VACUUM å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# %% [4] åŸ·è¡Œ VACUUM\n",
    "cursor.execute(\"VACUUM (DISABLE_PAGE_SKIPPING, VERBOSE) test_fragmentation\")\n",
    "print(\"ğŸ§¹ VACUUM å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ç¢ç‰‡åŒ–å¾Œ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index_size</th>\n",
       "      <td>133 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_scans</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_read</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_fetched</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btree_depth</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_page</th>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_size_mb</th>\n",
       "      <td>133 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_fanout</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ç¢ç‰‡åŒ–å¾Œ\n",
       "index_size      133 MB\n",
       "index_scans          0\n",
       "tuples_read          0\n",
       "tuples_fetched       0\n",
       "btree_depth          2\n",
       "root_page          412\n",
       "index_size_mb   133 MB\n",
       "avg_fanout           1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [5] ä¿®æ­£ç‰ˆç¢ç‰‡åŒ–åˆ†æå‡½æ•¸\n",
    "def analyze_fragmentation():\n",
    "    try:\n",
    "        # ç²å–ç´¢å¼•çµ±è¨ˆ\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \n",
    "                pg_size_pretty(pg_relation_size('test_fragmentation_pkey'::regclass)),\n",
    "                idx_scan,\n",
    "                idx_tup_read,\n",
    "                idx_tup_fetch\n",
    "            FROM pg_stat_all_indexes\n",
    "            WHERE indexrelid = 'test_fragmentation_pkey'::regclass\n",
    "        \"\"\")\n",
    "        stats = cursor.fetchone()\n",
    "        \n",
    "        # ç²å–é é¢å…ƒæ•¸æ“šï¼ˆä¿®æ­£ç±»å‹è½¬æ¢å’Œå­—æ®µï¼‰\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \n",
    "                level as btree_depth,\n",
    "                root as root_page,\n",
    "                pg_size_pretty(pg_relation_size('test_fragmentation_pkey')) AS index_size_mb\n",
    "            FROM bt_metap('test_fragmentation_pkey')\n",
    "        \"\"\")\n",
    "        page_stats = cursor.fetchone()\n",
    "\n",
    "        return {\n",
    "            # åŸºç¡€ç»Ÿè®¡\n",
    "            \"index_size\": stats[0],\n",
    "            \"index_scans\": stats[1],\n",
    "            \"tuples_read\": stats[2],\n",
    "            \"tuples_fetched\": stats[3],\n",
    "            \n",
    "            # B-Tree ç»“æ„å…ƒæ•°æ®\n",
    "            \"btree_depth\": page_stats[0],\n",
    "            \"root_page\": page_stats[1],  # ä¿®æ­£å­—æ®µå\n",
    "            \"index_size_mb\": page_stats[2],\n",
    "            \n",
    "            # æ–°å¢é‡è¦æŒ‡æ ‡\n",
    "            \"avg_fanout\": calculate_fanout(page_stats[0])  # æ·»åŠ B-Treeæ‰‡å‡ºè®¡ç®—\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"åˆ†æé”™è¯¯: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# æ–°å¢è¾…åŠ©å‡½æ•°\n",
    "def calculate_fanout(btree_depth):\n",
    "    \"\"\"è®¡ç®—B-Treeå¹³å‡æ‰‡å‡ºç³»æ•°\"\"\"\n",
    "    if btree_depth < 2:\n",
    "        return None\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            pg_relpages('test_fragmentation_pkey'::regclass)::float,\n",
    "            reltuples\n",
    "        FROM pg_class\n",
    "        WHERE relname = 'test_fragmentation_pkey'\n",
    "    \"\"\")\n",
    "    total_pages, total_tuples = cursor.fetchone()\n",
    "    return round((total_tuples ** (1/btree_depth)) / 1000)  # ä»¥åƒä¸ºå•ä½\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡åˆ†æ\n",
    "fragmented = analyze_fragmentation()\n",
    "df_frag = pd.DataFrame([fragmented]).T.rename(columns={0: 'ç¢ç‰‡åŒ–å¾Œ'})\n",
    "df_frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ REINDEX å®Œæˆ | è€—æ™‚: 0.4s\n"
     ]
    }
   ],
   "source": [
    "# %% [6] åŸ·è¡Œ REINDEX\n",
    "def perform_reindex():\n",
    "    start = time.time()\n",
    "    cursor.execute(\"REINDEX INDEX test_fragmentation_pkey\")\n",
    "    print(f\"ğŸ”„ REINDEX å®Œæˆ | è€—æ™‚: {time.time()-start:.1f}s\")\n",
    "\n",
    "perform_reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ç¢ç‰‡åŒ–å¾Œ</th>\n",
       "      <th>REINDEXå¾Œ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index_size</th>\n",
       "      <td>133 MB</td>\n",
       "      <td>20 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_scans</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_read</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_fetched</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btree_depth</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_page</th>\n",
       "      <td>412</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_size_mb</th>\n",
       "      <td>133 MB</td>\n",
       "      <td>20 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_fanout</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ç¢ç‰‡åŒ–å¾Œ REINDEXå¾Œ\n",
       "index_size      133 MB    20 MB\n",
       "index_scans          0        0\n",
       "tuples_read          0        0\n",
       "tuples_fetched       0        0\n",
       "btree_depth          2        2\n",
       "root_page          412      290\n",
       "index_size_mb   133 MB    20 MB\n",
       "avg_fanout           1        1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [7] REINDEX å¾Œåˆ†æ\n",
    "reindexed = analyze_fragmentation()\n",
    "\n",
    "# åˆä½µæ¯”è¼ƒæ•¸æ“š\n",
    "df_compare = pd.DataFrame([fragmented, reindexed], index=['ç¢ç‰‡åŒ–å¾Œ', 'REINDEXå¾Œ'])\n",
    "df_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¼ æ•¸æ“šåº«é€£æ¥å·²é—œé–‰ï¼Œautovacuum å·²å•Ÿç”¨\n"
     ]
    }
   ],
   "source": [
    "# %% [9] æ¸…ç†ç’°å¢ƒ\n",
    "cursor.execute(\"ALTER TABLE test_fragmentation SET (autovacuum_enabled = on)\")\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"ğŸ§¼ æ•¸æ“šåº«é€£æ¥å·²é—œé–‰ï¼Œautovacuum å·²å•Ÿç”¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

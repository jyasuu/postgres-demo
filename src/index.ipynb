{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %% [1] 安裝依賴 & 導入庫\n",
    "!pip install psycopg2-binary matplotlib pandas --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 配置數據庫連接 (根據你的環境修改)\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# 建立連接\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 測試表創建完成，autovacuum 已禁用\n",
      "📥 已插入 1000000 行初始數據\n"
     ]
    }
   ],
   "source": [
    "# %% [2] 初始化測試表\n",
    "def init_test_table():\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS test_fragmentation;\n",
    "            CREATE TABLE test_fragmentation (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                random_data TEXT,\n",
    "                created_at TIMESTAMP DEFAULT NOW()\n",
    "            );\n",
    "            ALTER TABLE test_fragmentation SET (autovacuum_enabled = off);\n",
    "        \"\"\")\n",
    "        print(\"✅ 測試表創建完成，autovacuum 已禁用\")\n",
    "        \n",
    "        # 插入初始數據\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO test_fragmentation (random_data)\n",
    "            SELECT md5(random()::text)\n",
    "            FROM generate_series(1, 1000000)\n",
    "        \"\"\")\n",
    "        print(f\"📥 已插入 {cursor.rowcount} 行初始數據\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 初始化錯誤: {str(e)}\")\n",
    "\n",
    "init_test_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♻️ 週期 1/10 | 更新: 98102, 刪除: 39514, 插入: 200000 | 耗時: 1.3s\n",
      "♻️ 週期 2/10 | 更新: 178022, 刪除: 70881, 插入: 200000 | 耗時: 1.9s\n",
      "♻️ 週期 3/10 | 更新: 242497, 刪除: 97044, 插入: 200000 | 耗時: 2.1s\n",
      "♻️ 週期 4/10 | 更新: 294313, 刪除: 117860, 插入: 200000 | 耗時: 3.3s\n",
      "♻️ 週期 5/10 | 更新: 335783, 刪除: 134734, 插入: 200000 | 耗時: 3.4s\n",
      "♻️ 週期 6/10 | 更新: 367568, 刪除: 147134, 插入: 200000 | 耗時: 3.3s\n",
      "♻️ 週期 7/10 | 更新: 394356, 刪除: 157221, 插入: 200000 | 耗時: 3.1s\n",
      "♻️ 週期 8/10 | 更新: 415219, 刪除: 165758, 插入: 200000 | 耗時: 5.3s\n",
      "♻️ 週期 9/10 | 更新: 432903, 刪除: 173368, 插入: 200000 | 耗時: 3.2s\n",
      "♻️ 週期 10/10 | 更新: 446868, 刪除: 178552, 插入: 200000 | 耗時: 3.1s\n"
     ]
    }
   ],
   "source": [
    "# %% [3] 製造碎片化\n",
    "def create_fragmentation(cycles=10):\n",
    "    try:\n",
    "        for cycle in range(1, cycles+1):\n",
    "            start = time.time()\n",
    "            \n",
    "            # 更新操作\n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE test_fragmentation\n",
    "                SET random_data = md5(random()::text)\n",
    "                WHERE random() < 0.5\n",
    "            \"\"\")\n",
    "            updated = cursor.rowcount\n",
    "            \n",
    "            # 刪除操作\n",
    "            cursor.execute(\"\"\"\n",
    "                DELETE FROM test_fragmentation\n",
    "                WHERE random() < 0.2\n",
    "            \"\"\")\n",
    "            deleted = cursor.rowcount\n",
    "            \n",
    "            # 插入操作\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO test_fragmentation (random_data)\n",
    "                SELECT md5(random()::text)\n",
    "                FROM generate_series(1, 200000)\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"♻️ 週期 {cycle}/{cycles} | \"\n",
    "                  f\"更新: {updated}, 刪除: {deleted}, 插入: {200000} | \"\n",
    "                  f\"耗時: {time.time()-start:.1f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 碎片化操作錯誤: {str(e)}\")\n",
    "\n",
    "create_fragmentation(cycles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 VACUUM 完成\n"
     ]
    }
   ],
   "source": [
    "# %% [4] 執行 VACUUM\n",
    "cursor.execute(\"VACUUM (DISABLE_PAGE_SKIPPING, VERBOSE) test_fragmentation\")\n",
    "print(\"🧹 VACUUM 完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>碎片化後</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index_size</th>\n",
       "      <td>133 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_scans</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_read</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_fetched</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btree_depth</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_page</th>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_size_mb</th>\n",
       "      <td>133 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_fanout</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  碎片化後\n",
       "index_size      133 MB\n",
       "index_scans          0\n",
       "tuples_read          0\n",
       "tuples_fetched       0\n",
       "btree_depth          2\n",
       "root_page          412\n",
       "index_size_mb   133 MB\n",
       "avg_fanout           1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [5] 修正版碎片化分析函數\n",
    "def analyze_fragmentation():\n",
    "    try:\n",
    "        # 獲取索引統計\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \n",
    "                pg_size_pretty(pg_relation_size('test_fragmentation_pkey'::regclass)),\n",
    "                idx_scan,\n",
    "                idx_tup_read,\n",
    "                idx_tup_fetch\n",
    "            FROM pg_stat_all_indexes\n",
    "            WHERE indexrelid = 'test_fragmentation_pkey'::regclass\n",
    "        \"\"\")\n",
    "        stats = cursor.fetchone()\n",
    "        \n",
    "        # 獲取頁面元數據（修正类型转换和字段）\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \n",
    "                level as btree_depth,\n",
    "                root as root_page,\n",
    "                pg_size_pretty(pg_relation_size('test_fragmentation_pkey')) AS index_size_mb\n",
    "            FROM bt_metap('test_fragmentation_pkey')\n",
    "        \"\"\")\n",
    "        page_stats = cursor.fetchone()\n",
    "\n",
    "        return {\n",
    "            # 基础统计\n",
    "            \"index_size\": stats[0],\n",
    "            \"index_scans\": stats[1],\n",
    "            \"tuples_read\": stats[2],\n",
    "            \"tuples_fetched\": stats[3],\n",
    "            \n",
    "            # B-Tree 结构元数据\n",
    "            \"btree_depth\": page_stats[0],\n",
    "            \"root_page\": page_stats[1],  # 修正字段名\n",
    "            \"index_size_mb\": page_stats[2],\n",
    "            \n",
    "            # 新增重要指标\n",
    "            \"avg_fanout\": calculate_fanout(page_stats[0])  # 添加B-Tree扇出计算\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"分析错误: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 新增辅助函数\n",
    "def calculate_fanout(btree_depth):\n",
    "    \"\"\"计算B-Tree平均扇出系数\"\"\"\n",
    "    if btree_depth < 2:\n",
    "        return None\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            pg_relpages('test_fragmentation_pkey'::regclass)::float,\n",
    "            reltuples\n",
    "        FROM pg_class\n",
    "        WHERE relname = 'test_fragmentation_pkey'\n",
    "    \"\"\")\n",
    "    total_pages, total_tuples = cursor.fetchone()\n",
    "    return round((total_tuples ** (1/btree_depth)) / 1000)  # 以千为单位\n",
    "\n",
    "# 第一次分析\n",
    "fragmented = analyze_fragmentation()\n",
    "df_frag = pd.DataFrame([fragmented]).T.rename(columns={0: '碎片化後'})\n",
    "df_frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 REINDEX 完成 | 耗時: 0.4s\n"
     ]
    }
   ],
   "source": [
    "# %% [6] 執行 REINDEX\n",
    "def perform_reindex():\n",
    "    start = time.time()\n",
    "    cursor.execute(\"REINDEX INDEX test_fragmentation_pkey\")\n",
    "    print(f\"🔄 REINDEX 完成 | 耗時: {time.time()-start:.1f}s\")\n",
    "\n",
    "perform_reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>碎片化後</th>\n",
       "      <th>REINDEX後</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index_size</th>\n",
       "      <td>133 MB</td>\n",
       "      <td>20 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_scans</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_read</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuples_fetched</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btree_depth</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_page</th>\n",
       "      <td>412</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_size_mb</th>\n",
       "      <td>133 MB</td>\n",
       "      <td>20 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_fanout</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  碎片化後 REINDEX後\n",
       "index_size      133 MB    20 MB\n",
       "index_scans          0        0\n",
       "tuples_read          0        0\n",
       "tuples_fetched       0        0\n",
       "btree_depth          2        2\n",
       "root_page          412      290\n",
       "index_size_mb   133 MB    20 MB\n",
       "avg_fanout           1        1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [7] REINDEX 後分析\n",
    "reindexed = analyze_fragmentation()\n",
    "\n",
    "# 合併比較數據\n",
    "df_compare = pd.DataFrame([fragmented, reindexed], index=['碎片化後', 'REINDEX後'])\n",
    "df_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧼 數據庫連接已關閉，autovacuum 已啟用\n"
     ]
    }
   ],
   "source": [
    "# %% [9] 清理環境\n",
    "cursor.execute(\"ALTER TABLE test_fragmentation SET (autovacuum_enabled = on)\")\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"🧼 數據庫連接已關閉，autovacuum 已啟用\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

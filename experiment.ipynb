{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp312-cp312-linux_x86_64.whl\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, psycopg2, numpy, pandas\n",
      "Successfully installed numpy-2.1.2 pandas-2.2.3 psycopg2-2.9.10 pytz-2024.2 tzdata-2024.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bitmap Heap Scan on public.large_table  (cost=19.18..1079.42 rows=400 width=68) (actual time=0.054..0.872 rows=155 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "(\"  Recheck Cond: (large_table.long_text ~~* '%zbc%'::text)\",)\n",
      "('  Heap Blocks: exact=153',)\n",
      "('  Buffers: shared hit=157',)\n",
      "('  ->  Bitmap Index Scan on idx_text  (cost=0.00..19.08 rows=400 width=0) (actual time=0.022..0.023 rows=155 loops=1)',)\n",
      "(\"        Index Cond: (large_table.long_text ~~* '%zbc%'::text)\",)\n",
      "('        Buffers: shared hit=4',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=13',)\n",
      "('Planning Time: 0.166 ms',)\n",
      "('Execution Time: 0.891 ms',)\n",
      "\n",
      "\n",
      "('Bitmap Heap Scan on public.large_table  (cost=88257.77..88595.92 rows=100 width=68) (actual time=10.318..47.067 rows=29 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "('  Recheck Cond: (large_table.json_data @@ \\'($.\"A\" like_regex \".*zbc.*\")\\'::jsonpath)',)\n",
      "('  Rows Removed by Index Recheck: 9971',)\n",
      "('  Heap Blocks: exact=2500',)\n",
      "('  Buffers: shared hit=2671',)\n",
      "('  ->  Bitmap Index Scan on idx_json  (cost=0.00..88257.75 rows=100 width=0) (actual time=9.736..9.736 rows=10000 loops=1)',)\n",
      "('        Index Cond: (large_table.json_data @@ \\'($.\"A\" like_regex \".*zbc.*\")\\'::jsonpath)',)\n",
      "('        Buffers: shared hit=171',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=7',)\n",
      "('Planning Time: 0.037 ms',)\n",
      "('Execution Time: 47.081 ms',)\n",
      "\n",
      "\n",
      "('Bitmap Heap Scan on public.large_table  (cost=13.35..351.50 rows=100 width=68) (actual time=0.854..14.371 rows=3935 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "('  Recheck Cond: (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath)',)\n",
      "('  Heap Blocks: exact=2173',)\n",
      "('  Buffers: shared hit=2177',)\n",
      "('  ->  Bitmap Index Scan on idx_json  (cost=0.00..13.32 rows=100 width=0) (actual time=0.562..0.563 rows=3935 loops=1)',)\n",
      "('        Index Cond: (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath)',)\n",
      "('        Buffers: shared hit=4',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=4',)\n",
      "('Planning Time: 0.070 ms',)\n",
      "('Execution Time: 14.522 ms',)\n",
      "\n",
      "\n",
      "('Bitmap Heap Scan on public.large_table  (cost=32.66..48.24 rows=4 width=68) (actual time=0.511..0.845 rows=48 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "('  Recheck Cond: ((large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath) AND (large_table.long_text ~~* \\'%zbc%\\'::text))',)\n",
      "('  Heap Blocks: exact=48',)\n",
      "('  Buffers: shared hit=56',)\n",
      "('  ->  BitmapAnd  (cost=32.66..32.66 rows=4 width=0) (actual time=0.488..0.489 rows=0 loops=1)',)\n",
      "('        Buffers: shared hit=8',)\n",
      "('        ->  Bitmap Index Scan on idx_json  (cost=0.00..13.32 rows=100 width=0) (actual time=0.394..0.394 rows=3935 loops=1)',)\n",
      "('              Index Cond: (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath)',)\n",
      "('              Buffers: shared hit=4',)\n",
      "('        ->  Bitmap Index Scan on idx_text  (cost=0.00..19.08 rows=400 width=0) (actual time=0.018..0.018 rows=155 loops=1)',)\n",
      "(\"              Index Cond: (large_table.long_text ~~* '%zbc%'::text)\",)\n",
      "('              Buffers: shared hit=4',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=2',)\n",
      "('Planning Time: 0.056 ms',)\n",
      "('Execution Time: 0.857 ms',)\n"
     ]
    }
   ],
   "source": [
    "# 1. Connect to Postgres using Jupyter\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to Postgres\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 2. Create a large table with 1 million rows\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE large_table (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        long_text TEXT,\n",
    "        json_data JSONB\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Generate test data\n",
    "import string\n",
    "import random\n",
    "\n",
    "for i in range(10_000):\n",
    "    long_text = ''.join(random.choices(string.ascii_letters + string.digits, k=500))\n",
    "    json_data = {\n",
    "        \"A\": ''.join(random.choices(string.ascii_letters + string.digits, k=500)),\n",
    "        \"B\": [random.randint(1, 100) for _ in range(50)]\n",
    "    }\n",
    "    cursor.execute(\"INSERT INTO large_table (long_text, json_data) VALUES (%s, %s)\", (long_text, json.dumps(json_data)))\n",
    "\n",
    "# conn.commit()\n",
    "\n",
    "cursor.execute(\"CREATE EXTENSION pg_trgm\")\n",
    "# 3. Create indexes\n",
    "cursor.execute(\"CREATE INDEX idx_json ON large_table USING GIN (json_data jsonb_path_ops)\")\n",
    "cursor.execute(\"CREATE INDEX idx_text ON large_table USING GIN (long_text gin_trgm_ops)\")\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute(\"set enable_seqscan=false\")\n",
    "\n",
    "\n",
    "# 4. Explain analyze for searching long text\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT)  SELECT * FROM large_table WHERE long_text iLIKE '%zbc%'\")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "print(\"\\n\")\n",
    "# 5. Explain analyze for searching JSON\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT) SELECT * FROM large_table WHERE json_data  @@ '$.A like_regex \\\".*zbc.*\\\"' \")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "print(\"\\n\")\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT) SELECT * FROM large_table WHERE json_data  @? '$.B[*] ? (@ == 5 )' \")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "print(\"\\n\")\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT) SELECT * FROM large_table WHERE long_text iLIKE '%zbc%' and json_data  @? '$.B[*] ? (@ == 5 )' \")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bitmap Heap Scan on public.large_table  (cost=30.07..45.65 rows=4 width=68) (actual time=0.095..0.611 rows=60 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "('  Recheck Cond: ((large_table.long_text ~~* \\'%zbc%\\'::text) AND (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath))',)\n",
      "('  Heap Blocks: exact=60',)\n",
      "('  Buffers: shared hit=68',)\n",
      "('  ->  Bitmap Index Scan on idx_combine  (cost=0.00..30.06 rows=4 width=0) (actual time=0.061..0.062 rows=60 loops=1)',)\n",
      "('        Index Cond: ((large_table.long_text ~~* \\'%zbc%\\'::text) AND (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath))',)\n",
      "('        Buffers: shared hit=8',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=19',)\n",
      "('Planning Time: 0.170 ms',)\n",
      "('Execution Time: 0.628 ms',)\n",
      "\n",
      "\n",
      "('Bitmap Heap Scan on public.large_table  (cost=30.07..45.65 rows=4 width=68) (actual time=0.069..0.504 rows=60 loops=1)',)\n",
      "('  Output: id, long_text, json_data',)\n",
      "('  Recheck Cond: ((large_table.long_text ~~* \\'%zbc%\\'::text) AND (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath))',)\n",
      "('  Heap Blocks: exact=60',)\n",
      "('  Buffers: shared hit=68',)\n",
      "('  ->  Bitmap Index Scan on idx_combine  (cost=0.00..30.06 rows=4 width=0) (actual time=0.053..0.053 rows=60 loops=1)',)\n",
      "('        Index Cond: ((large_table.long_text ~~* \\'%zbc%\\'::text) AND (large_table.json_data @? \\'$.\"B\"[*]?(@ == 5)\\'::jsonpath))',)\n",
      "('        Buffers: shared hit=8',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=1',)\n",
      "('Planning Time: 0.037 ms',)\n",
      "('Execution Time: 0.515 ms',)\n"
     ]
    }
   ],
   "source": [
    "# 1. Connect to Postgres using Jupyter\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to Postgres\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 2. Create a large table with 1 million rows\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE large_table (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        long_text TEXT,\n",
    "        json_data JSONB\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Generate test data\n",
    "import string\n",
    "import random\n",
    "\n",
    "for i in range(10_000):\n",
    "    long_text = ''.join(random.choices(string.ascii_letters + string.digits, k=500))\n",
    "    json_data = {\n",
    "        \"A\": ''.join(random.choices(string.ascii_letters + string.digits, k=500)),\n",
    "        \"B\": [random.randint(1, 100) for _ in range(50)]\n",
    "    }\n",
    "    cursor.execute(\"INSERT INTO large_table (long_text, json_data) VALUES (%s, %s)\", (long_text, json.dumps(json_data)))\n",
    "\n",
    "# conn.commit()\n",
    "\n",
    "cursor.execute(\"CREATE EXTENSION pg_trgm\")\n",
    "# 3. Create indexes\n",
    "cursor.execute(\"CREATE INDEX idx_combine ON large_table USING GIN (long_text gin_trgm_ops,json_data jsonb_path_ops)\")\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute(\"set enable_seqscan=false\")\n",
    "\n",
    "\n",
    "# 4. Explain analyze for searching long text\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT) SELECT * FROM large_table WHERE json_data  @? '$.B[*] ? (@ == 5 )' and long_text iLIKE '%zbc%' \")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "print(\"\\n\")\n",
    "cursor.execute(\"EXPLAIN  (ANALYZE ,VERBOSE ,COSTS ,BUFFERS ,TIMING ,SUMMARY,FORMAT TEXT) SELECT * FROM large_table WHERE long_text iLIKE '%zbc%' and json_data  @? '$.B[*] ? (@ == 5 )' \")\n",
    "print(\"\\n\".join(map(str, cursor.fetchall())))\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
